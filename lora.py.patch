--- lora.py	2023-12-09 15:55:14.976962981 -0600
+++ lora-patched.py	2023-12-09 17:19:49.942768804 -0600
@@ -26,14 +26,31 @@
     load_checkpoint,
     num_parameters,
 )
-from scripts.prepare_alpaca import generate_prompt
+#from scripts.prepare_alpaca import generate_prompt
+def generate_prompt(example: dict) -> str:
+    """Generates a standardized message to prompt the model with an instruction, optional input and a
+    'response' field."""
+
+    if example["input"]:
+        return (
+            "Below is an instruction that describes a task, paired with an input that provides further context. "
+            "Write a response that appropriately completes the request.\n\n"
+            f"### Instruction:\n{example['instruction']}\n\n### Input:\n{example['input']}\n\n### Response:"
+        )
+    return (
+        "Below is an instruction that describes a task. "
+        "Write a response that appropriately completes the request.\n\n"
+        f"### Instruction:\n{example['instruction']}\n\n### Response:"
+    )
 
 eval_interval = 100
 save_interval = 100
 eval_iters = 100
 eval_max_new_tokens = 100
 log_interval = 1
-devices = 1
+devices_per_node = int(os.environ["SLURM_GPUS_ON_NODE"])
+num_nodes = int(os.environ["SLURM_NNODES"])
+devices = num_nodes * devices_per_node
 
 # Hyperparameters
 learning_rate = 3e-4
@@ -91,7 +108,7 @@
         strategy = "auto"
 
     logger = CSVLogger(out_dir.parent, out_dir.name, flush_logs_every_n_steps=log_interval)
-    fabric = L.Fabric(devices=devices, strategy=strategy, precision=precision, loggers=logger, plugins=plugins)
+    fabric = L.Fabric(devices=devices_per_node, num_nodes=num_nodes, strategy=strategy, precision=precision, loggers=logger, plugins=plugins)
     fabric.print(hparams)
     fabric.launch(main, data_dir, checkpoint_dir, out_dir)
 
